{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "try:\n",
    "    from urllib2 import urlopen\n",
    "except ImportError:\n",
    "    from urllib.request import urlopen\n",
    "import dateutil\n",
    "from dateutil.parser import *\n",
    "from datetime import datetime\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process statewise GERMAN VERSION \n",
    "\n",
    "\n",
    "\n",
    "def process_state_DE(state):\n",
    "\n",
    "    agile_regex = re.compile(r'\\bagility\\b|\\bagil\\w{0,2}\\b|\\bagilitÃ¤t\\b', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "    agile_method_regex = re.compile(r'\\bagil\\w{0,2}\\b((?![.]|agil\\w{0,2}).)*?\\bmethod\\w*?\\b', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "    agile_context_regex = re.compile(r'\\s*([^\\s]+?)\\s+([^\\s]+?)\\s+([^\\s]+?)\\s+([^\\s]+?)\\s+agil.*?\\s+([^\\s]+)\\s+([^\\s]+?)\\s+([^\\s]+?)\\s+([^\\s]+?)\\s+', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "    csv_main = csv.DictReader(open(\"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/1_Data_Collection/DATA/CSVs/Germany/agile_sites_output_Germany_{}.csv\".format(state)), fieldnames=[\"id\", 'url', 'domain', 'date1', 'date2', 'date3', 'heading'])\n",
    "    array = {}\n",
    "    for line in csv_main: \n",
    "        array[line[\"id\"]] = line\n",
    "    text_dir = \"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/2_Data_Processing/DATA/TextFiles/Germany/{}\".format(state)\n",
    "    pathlib.Path(text_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for id, line in array.items():\n",
    "        print(\"processing {}\".format(id))\n",
    "        id = line[\"id\"]\n",
    "        domain = line[\"domain\"]\n",
    "        path = '/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/1_Data_Collection/DATA/HTMLs/Germany/{}/{}/{}.html'.format(state, domain, id)\n",
    "        try:  \n",
    "            soup = BeautifulSoup(open(path), \"html.parser\")\n",
    "        except UnicodeDecodeError:\n",
    "            soup = BeautifulSoup(open(path, encoding='windows-1252'), \"html.parser\")    \n",
    "                \n",
    "        #deleting all the Script and Style Elements\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()    # rip it out\n",
    "                \n",
    "         # get text\n",
    "        doctext = soup.get_text()\n",
    "\n",
    "        # break into lines and remove leading and trailing space on each\n",
    "        lines = (line.strip() for line in doctext.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "        doctext = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        \n",
    "        #encoding safely as utf-8\n",
    "        doctext.encode('utf-8')\n",
    "        \n",
    "        #old 'simple' cleaning         \n",
    "        doctext = soup.get_text().replace(\"\\n\", \" \")\n",
    "        with open(\"{}/{}.txt\".format(text_dir, id), \"w\") as textfile:\n",
    "            textfile.write(doctext)\n",
    "        \n",
    "        #Getting date4\n",
    "        date4_element = soup.select_one(\"span.date\")\n",
    "        date4 = \"\"\n",
    "        if date4_element is not None:\n",
    "            date4 = date4_element.get_text()\n",
    "        \n",
    "        #Getting date5\n",
    "\n",
    "        htmlparser = etree.HTMLParser()    \n",
    "        try:\n",
    "            tree = etree.parse(open(path), htmlparser)\n",
    "        except UnicodeDecodeError:\n",
    "            tree = etree.parse(open(path, encoding='windows-1252'), htmlparser)\n",
    "        date5 = tree.xpath(\"substring(substring-after(/html//script[@type='application/ld+json']/text(), 'datePublished'), 4, 23)\")\n",
    "\n",
    "        # a special cases for date 5\n",
    "        date5_1 = tree.xpath(\"substring(substring-after(/html//script[@type='application/ld+json']/text(), 'datePublished'), 4, 25)\")\n",
    "\n",
    "\n",
    "        # Getting date6\n",
    "\n",
    "        date6_element = soup.select_one(\"h1#page-title + p\")\n",
    "        date6 = \"\"\n",
    "        if date6_element is not None:\n",
    "            date6 = date6_element.get_text()\n",
    "\n",
    "\n",
    "        # Getting date7 from National Archives --> the date the site was archived on --> the date the site was released on would have been even earlier\n",
    "\n",
    "        date7 = tree.xpath(\"substring(substring-after(/html/head/script/text(), 'timestamp'),9,14)\")\n",
    "\n",
    "\n",
    "        # assinging the already crawled dates\n",
    "        date1 = line[\"date1\"]\n",
    "        date2 = line[\"date2\"]\n",
    "\n",
    "\n",
    "        # Storing the oldest date as final date variable in python date format\n",
    "        date_vars = [date1, date2, date4, date5, date5_1, date6, date7]\n",
    "        \n",
    "        final_date = None \n",
    "\n",
    "        for date_var in date_vars:\n",
    "            try:\n",
    "                if final_date is None:\n",
    "                    final_date = parse(date_var, ignoretz = True)\n",
    "                elif parse(date_var, ignoretz=True) < final_date:\n",
    "                    final_date = parse(date_var, ignoretz=True)\n",
    "            except dateutil.parser._parser.ParserError:\n",
    "                pass \n",
    "\n",
    "\n",
    "        #finding the matches for agile and agility\n",
    "        agile_term = []\n",
    "        agile_term = agile_regex.findall(doctext)\n",
    "\n",
    "        #removing white space, dot etc. from the end of the term\n",
    "        \n",
    "        signs=[' ', '.',':',';']\n",
    "        \n",
    "       # print(agile_term_match)\n",
    "        agile_term=[]\n",
    "        \n",
    "        if agile_term_match != []:\n",
    "            for item in agile_term_match:\n",
    "                if item[-1] in signs:\n",
    "                   # print(\"item\", item)\n",
    "                    newitem = item[:-1]\n",
    "                   # print(\"newitem\", newitem)\n",
    "                else:\n",
    "                    newitem = item\n",
    "                newitem = newitem.lower()\n",
    "                agile_term.append(newitem)\n",
    "\n",
    "        #print(\"newitem\", newitem)\n",
    "        #print(\"agile_term\",agile_term)\n",
    "\n",
    "        #finding the matches for agile...methods\n",
    "        agile_method = []\n",
    "        agile_method = agile_method_regex.findall(doctext.lower())\n",
    "\n",
    "\n",
    "        # finding the context for the agile\n",
    "        agile_context = []\n",
    "        agile_context = agile_context_regex.search(doctext)\n",
    "\n",
    "        agile_context_pre = \"\"\n",
    "        agile_context_post = \"\"\n",
    "        \n",
    "        if agile_context is not None:\n",
    "            agile_context_pre = \" \".join(agile_context.group(1,2,3,4))\n",
    "            agile_context_post = \" \".join(agile_context.group(5,6,7,8))\n",
    "        \n",
    "\n",
    "        # assigning all the variables to the items\n",
    "\n",
    "        if len(agile_term) == 0:\n",
    "            line[\"agile_term\"] = \"\" \n",
    "        else:\n",
    "            line[\"agile_term\"] = \",\".join(agile_term)\n",
    "        \n",
    "        if len(agile_method) == 0:\n",
    "            line[\"agile_method\"] = \"\" \n",
    "        else:\n",
    "            line[\"agile_method\"] = \",\".join(agile_method)\n",
    "\n",
    "        line[\"agile_context_pre\"] = agile_context_pre\n",
    "        line[\"agile_context_post\"] = agile_context_post \n",
    "        line[\"date4\"] = date4\n",
    "        line[\"date5\"] = date5\n",
    "        line[\"date5_1\"] = date5_1\n",
    "        line[\"date6\"] = date6\n",
    "        line[\"date7\"] = date7\n",
    "        line[\"final_date\"] = final_date\n",
    "        line[\"country\"] = \"Germany\"\n",
    "        line[\"level\"] = state\n",
    "        line[\"text_file_loc\"] = \"{}/{}.txt\".format(text_dir, id)\n",
    "    \n",
    "    outputfile = open(\"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/2_Data_Processing/DATA/CSVs/Germany/{}.csv\".format(state), \"w\")\n",
    "    writer = csv.DictWriter(outputfile, fieldnames=[\"id\", \"country\", \"level\", 'url', 'domain', 'date1', 'date2', 'date3', 'date4', 'date5', 'date5_1', 'date6', 'date7', 'final_date', 'heading', 'agile_term', 'agile_method', 'agile_context_pre', 'agile_context_post', 'text_file_loc'])\n",
    "    writer.writeheader()\n",
    "    for id, line in array.items():\n",
    "        writer.writerow(line)\n",
    "    outputfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process statewise UK VERSION --> type \"General\"\n",
    "\n",
    "\n",
    "def process_state_UK(state):\n",
    "\n",
    "    agile_regex = re.compile(r'\\bagility[ .,:;]|\\bagile[ .,:;]', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "    agile_method_regex = re.compile(r'\\bagile\\b(?:(?![.]|agile).)*?\\bmethod\\w*?\\b', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "    agile_context_regex = re.compile(r'\\s*([^\\s]+?)\\s+([^\\s]+?)\\s+([^\\s]+?)\\s+([^\\s]+?)\\s+agil.*?\\s+([^\\s]+)\\s+([^\\s]+?)\\s+([^\\s]+?)\\s+([^\\s]+?)\\s+', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "    csv_main = csv.DictReader(open(\"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/1_Data_Collection/DATA/CSVs/UK/agile_sites_output_UK_{}.csv\".format(state)), fieldnames=[\"id\", 'url', 'domain', 'date1', 'date2', 'date3', 'heading'])\n",
    "    array = {}\n",
    "    for line in csv_main: \n",
    "        array[line[\"id\"]] = line\n",
    "    text_dir = \"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/2_Data_Processing/DATA/TextFiles/UK/{}\".format(state)\n",
    "    pathlib.Path(text_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for id, line in array.items():\n",
    "        print(\"processing {}\".format(id))\n",
    "        id = line[\"id\"]\n",
    "        domain = line[\"domain\"]\n",
    "        path = '/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/1_Data_Collection/DATA/HTMLs/UK/{}/{}/{}.html'.format(state, domain, id)\n",
    "        try:  \n",
    "            soup = BeautifulSoup(open(path), \"html.parser\")\n",
    "        except UnicodeDecodeError:\n",
    "            soup = BeautifulSoup(open(path, encoding='windows-1252'), \"html.parser\")    \n",
    "        \n",
    "        #deleting all the Script and Style Elements\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()    # rip it out\n",
    "                \n",
    "         # get text\n",
    "        doctext = soup.get_text()\n",
    "\n",
    "        # break into lines and remove leading and trailing space on each\n",
    "        lines = (line.strip() for line in doctext.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "        doctext = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        \n",
    "        #encoding safely as utf-8\n",
    "        doctext.encode('utf-8')\n",
    "        \n",
    "        #old 'simple' cleaning \n",
    "\n",
    "        #doctext = soup.get_text().replace(\"\\n\", \" \")\n",
    "        with open(\"{}/{}.txt\".format(text_dir, id), \"w\") as textfile:\n",
    "            textfile.write(text)\n",
    "        \n",
    "        #Getting date4\n",
    "        date4_element = soup.select_one(\"span.date\")\n",
    "        date4 = \"\"\n",
    "        if date4_element is not None:\n",
    "            date4 = date4_element.get_text()\n",
    "        \n",
    "        #Getting date5\n",
    "\n",
    "        htmlparser = etree.HTMLParser()    \n",
    "        try:\n",
    "            tree = etree.parse(open(path), htmlparser)\n",
    "        except UnicodeDecodeError:\n",
    "            tree = etree.parse(open(path, encoding='windows-1252'), htmlparser)\n",
    "        date5 = tree.xpath(\"substring(substring-after(/html//script[@type='application/ld+json']/text(), 'datePublished'), 4, 23)\")\n",
    "\n",
    "        # a special cases for date 5\n",
    "        date5_1 = tree.xpath(\"substring(substring-after(/html//script[@type='application/ld+json']/text(), 'datePublished'), 4, 25)\")\n",
    "\n",
    "\n",
    "        # Getting date6\n",
    "\n",
    "        date6_element = soup.select_one(\"h1#page-title + p\")\n",
    "        date6 = \"\"\n",
    "        if date6_element is not None:\n",
    "            date6 = date6_element.get_text()\n",
    "\n",
    "\n",
    "        # Getting date7 from National Archives --> the date the site was archived on --> the date the site was released on would have been even earlier\n",
    "\n",
    "        date7 = tree.xpath(\"substring(substring-after(/html/head/script/text(), 'timestamp'),9,14)\")\n",
    "\n",
    "\n",
    "        # assinging the already crawled dates\n",
    "        date1 = line[\"date1\"]\n",
    "        date2 = line[\"date2\"]\n",
    "\n",
    "\n",
    "        # Storing the oldest date as final date variable in python date format\n",
    "        date_vars = [date1, date2, date4, date5, date5_1, date6, date7]\n",
    "        \n",
    "        final_date = None \n",
    "\n",
    "        for date_var in date_vars:\n",
    "            try:\n",
    "                if final_date is None:\n",
    "                    final_date = parse(date_var, ignoretz = True)\n",
    "                elif parse(date_var, ignoretz=True) < final_date:\n",
    "                    final_date = parse(date_var, ignoretz=True)\n",
    "            except dateutil.parser._parser.ParserError:\n",
    "                pass \n",
    "\n",
    "\n",
    "        #finding the matches for agile and agility\n",
    "        agile_term_match = []\n",
    "        agile_term_match = agile_regex.findall(doctext)\n",
    "        \n",
    "        #removing white space, dot etc. from the end of the term\n",
    "        \n",
    "        signs=[' ', '.',':',';']\n",
    "        \n",
    "       # print(agile_term_match)\n",
    "        agile_term=[]\n",
    "        \n",
    "        if agile_term_match != []:\n",
    "            for item in agile_term_match:\n",
    "                if item[-1] in signs:\n",
    "                   # print(\"item\", item)\n",
    "                    newitem = item[:-1]\n",
    "                   # print(\"newitem\", newitem)\n",
    "                else:\n",
    "                    newitem = item\n",
    "                newitem = newitem.lower()\n",
    "                agile_term.append(newitem)\n",
    "\n",
    "        #print(\"newitem\", newitem)\n",
    "        #print(\"agile_term\",agile_term)\n",
    "\n",
    "        #finding the matches for agile...methods\n",
    "        agile_method = []\n",
    "        agile_method = agile_method_regex.findall(doctext.lower())\n",
    "\n",
    "\n",
    "\n",
    "        # finding the context for the agile\n",
    "        agile_context = []\n",
    "        agile_context = agile_context_regex.search(doctext)\n",
    "\n",
    "        agile_context_pre = \"\"\n",
    "        agile_context_post = \"\"\n",
    "        \n",
    "        if agile_context is not None:\n",
    "            agile_context_pre = \" \".join(agile_context.group(1,2,3,4))\n",
    "            agile_context_post = \" \".join(agile_context.group(5,6,7,8))\n",
    "        \n",
    "\n",
    "        # assigning all the variables to the items\n",
    "\n",
    "        if len(agile_term) == 0:\n",
    "            line[\"agile_term\"] = \"\" \n",
    "        else:\n",
    "            line[\"agile_term\"] = \",\".join(agile_term)\n",
    "        \n",
    "        if len(agile_method) == 0:\n",
    "            line[\"agile_method\"] = \"\" \n",
    "        else:\n",
    "            line[\"agile_method\"] = \",\".join(agile_method)\n",
    "\n",
    "        line[\"agile_context_pre\"] = agile_context_pre\n",
    "        line[\"agile_context_post\"] = agile_context_post \n",
    "        line[\"date4\"] = date4\n",
    "        line[\"date5\"] = date5\n",
    "        line[\"date5_1\"] = date5_1\n",
    "        line[\"date6\"] = date6\n",
    "        line[\"date7\"] = date7\n",
    "        line[\"final_date\"] = final_date\n",
    "        line[\"country\"] = \"Germany\"\n",
    "        line[\"level\"] = state\n",
    "        line[\"text_file_loc\"] = \"{}/{}.txt\".format(text_dir, id)\n",
    "        \n",
    "    outputfile = open(\"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/2_Data_Processing/DATA/CSVs/UK/{}.csv\".format(state), \"w\")\n",
    "    writer = csv.DictWriter(outputfile, fieldnames=[\"id\", \"country\", \"level\", 'url', 'domain', 'date1', 'date2', 'date3', 'date4', 'date5', 'date5_1', 'date6', 'date7', 'final_date', 'heading', 'agile_term', 'agile_method', 'agile_context_pre', 'agile_context_post', 'text_file_loc'])\n",
    "    writer.writeheader()\n",
    "    for id, line in array.items():\n",
    "        writer.writerow(line)\n",
    "    outputfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "processing d64b7c1c-cddf-3ef7-ab10-f6c32100fc36\nprocessing 001213a3-6bb1-374b-83ff-6d166d567933\nprocessing c41d71f9-6ced-3c39-a661-dd85dff2175c\nprocessing a36f0ef0-ec1b-33b6-aad4-45cda5defa48\nprocessing 4d89205c-ee61-3d36-bdcc-d9ec9b22a082\nprocessing 19dd6541-fe8a-3edb-835b-ab6d94423537\nprocessing 447443cc-ba1b-3d2b-b0b7-5390f81e6569\nprocessing af9dd497-d2a2-35ca-b48f-33c26d4476de\nprocessing 9e8cc26a-36ba-3046-bf44-5c1484f2f0b3\nprocessing 42f53033-7a47-39bf-ade6-3e3623083fb2\nprocessing 1c69cbda-86f6-348a-ba31-a53f12a9197e\nprocessing 83d20ea8-c770-37d6-b880-c7f329c5ced5\nprocessing 9f67207b-61f1-3521-88c4-b533f74a244b\nprocessing b0f2757b-c084-34a0-a104-e1bcbae826c8\nprocessing 68d31c56-39f1-3753-b29d-ac5842eac9d3\nprocessing 9e925771-d3a3-3b40-add7-fde6e74d97f2\nprocessing f470ba9c-6aa9-39a0-86e5-d560d928cd16\nprocessing 9b2b3bc8-d57f-345b-a4cc-66acb4144e91\nprocessing 2233b421-720a-391b-b517-ae3a5233afe4\nprocessing 242e8fc5-7383-3e83-bd2c-a00b7ee9b877\nprocessing 635cbcf2-0fe2-39cd-91b5-d1ad79a8440d\nprocessing 014e2d2f-779e-3685-aac6-47230e4a7942\nprocessing 57879f15-b1f3-3b02-b989-3a40fce1a6cd\nprocessing 0523e375-81c8-3230-81f6-d770b2147060\nprocessing c2afbd48-eb7e-30cb-b288-efab91085399\nprocessing 8f22648d-3f5f-3a1f-b2cc-8d5b65e966e7\nprocessing 8cb87387-f246-3f70-8c10-9425e4e6567a\nprocessing 0d290d17-f152-3f40-a363-333c7c93507d\nprocessing 774b610b-b621-3085-9216-16124b9d2dc8\nprocessing 717643c9-022f-3140-a6da-031c72efe84d\nprocessing f8ba56d5-fcb4-3041-879a-456c9de497ef\nprocessing 353baedc-edab-321f-af3e-e07015d82913\nprocessing b8903cb8-f48f-3593-9ff4-fac09858532e\nprocessing fed3dfdf-48da-3484-96c5-d67bd6fd3a32\nprocessing 50141327-3a3f-302b-916a-85af2bbefc3c\nprocessing 7118b8c9-6cb6-3975-bb7d-c5ce2de5c8ef\nprocessing a05a3327-ab85-3ab1-b313-da14439fb077\nprocessing 41e40ed8-83cd-31d7-ae03-0457636a977a\nprocessing 8ec9f66d-2c8b-32d8-b22d-bc16c6f0fc01\nprocessing 5614360e-96ac-328c-a992-da9ad31c3065\nprocessing d375d6b8-f36f-393e-8b41-2affc5c7bba2\nprocessing a0d97d33-886d-38a0-95f4-aee869267f4f\nprocessing ca04fc0b-9829-3a2b-95b9-e2c33281ffa1\nprocessing d759b78b-cc3d-3d82-8b3d-e83f2d89c715\nprocessing 37c8a228-ef45-3931-bac5-5019c698c5e9\nprocessing c70a1c5d-fa85-3a88-b25d-4403730a98ed\nprocessing 5f3bad21-3443-3db4-adaf-db20d117ad61\nprocessing 004c8d62-c543-3627-a29d-64283d265a36\nprocessing bca89a20-6803-3c81-a57f-1cd2294ddbf0\nprocessing 1a15c230-5a71-3dd0-a85e-c414c38f19df\nprocessing aeceec9d-2e57-351e-8e7b-c7a3024f94de\nprocessing fda72704-4748-32bd-84b9-50a66e5e726c\nprocessing 7b144d58-265d-333f-bec9-74c850942e07\nprocessing 75e9e979-c6ad-33ca-80b4-c1986f2468c8\nprocessing 6af013d4-b660-34b8-9d75-315d8089b521\nprocessing 823ca35d-0056-38c3-9480-bb95ffc2c515\nprocessing cea9b7f1-bbb7-308e-9a1c-68cc5da8876c\nprocessing 8c9f2897-84b0-3102-8ff0-bcdba0849043\nprocessing 0cb6e732-9f51-3d98-a98e-ab11e45d42a3\nprocessing 6fb7c733-bc60-3b01-9402-859441e70cfe\nprocessing 820d52be-59b5-3933-bf25-fda25dcb8aba\nprocessing a97e7c6e-5c74-3823-96d7-a84ce7489587\nprocessing 42e9bc3a-4628-3264-a973-2b4da99f012c\nprocessing 99bc860a-50fb-32a6-a8fc-9ecffc2494c1\nprocessing 85e74b27-e18f-339d-92fa-fed474397689\nprocessing 46f4e547-c4fe-3f86-9516-cfb69d092f07\nprocessing af71c7e9-5440-393b-8279-10c6aebe922d\nprocessing d2c9b90d-401d-3ca4-be67-3336588eec41\nprocessing de7752ec-b795-3463-b5c0-f94e7866b3ad\nprocessing 4586b102-357e-3e82-a162-02342a4e1b18\nprocessing 0be65cb5-4194-3615-b837-a6ef3a1b6db0\nprocessing 3827dfc9-64a5-3ed5-a1a2-3cb02a420aad\nprocessing b3eef5a9-4e9b-387b-a400-acdcec17b896\nprocessing 8d5d0fe5-73e9-39a5-ad8b-98b3f677089f\nprocessing 789c2001-6392-30ee-876c-95a72631857e\nprocessing 0db575da-5559-37c5-ad16-7c3a31f1e956\nprocessing a43b869b-8312-3556-8e3c-365e7e32a958\nprocessing f081e111-cc58-327f-9ab7-b658ce84cc37\nprocessing e366dd34-1af3-39fe-9a10-2ec296bf2b39\nprocessing cb56cf8b-8416-346a-ac67-588b5f1b33ec\nprocessing aca70065-8bbc-3d67-8de4-35012d4ecdec\nprocessing 105fbd0e-33b3-3a5c-8999-da9d53d83698\nprocessing e1c4209a-ee53-390d-b1a7-a3de728fd4ab\nprocessing 29b71149-fb61-3f3b-b9ec-4266b61e4fe6\nprocessing 50728431-5223-3fb2-b8e3-9ebc64f34fd6\nprocessing 47d261ab-e3f3-3881-ad20-5ecd1988734b\nprocessing da743fbd-3936-35a8-91b8-a9ead2c414cb\nprocessing 5bea9c36-7f15-3c2e-80c8-50b3c2ab1b51\nprocessing 22bacf7e-df5a-39db-9887-9a0d8aed26ff\nprocessing f96dc7dc-50de-3f16-8ccb-0f239ff2f9c4\nprocessing 43c0fbba-8838-3ba3-8b5e-9ea1a9eba180\nprocessing 031f2acd-ec89-31d8-9949-c4536f112028\nprocessing e70cb3c1-8b70-382d-9c9d-759d64aeae72\nprocessing e280cca3-7f41-351f-aaf6-fc0f91c3e9b5\nprocessing 49ddef4c-a71e-3ac5-8dc0-65ad596025b6\nprocessing 841aeae8-d85a-3839-a62b-bfecb23871ba\nprocessing 0c0005f9-69e3-3065-930c-f57d70713588\nprocessing 2f34a50f-c817-3d8a-9d4d-25a601afac6e\nprocessing ca861dbc-961b-381f-9d2d-b0f60e6d57dc\n"
    }
   ],
   "source": [
    "#Running processing for Germany\n",
    "process_state_DE(\"Federal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "5a63d-5ce8-3d4a-bead-e6baf3d3450c\nagile_term ['agile', 'agile']\nprocessing 0873ee12-e7a5-3be6-88db-341a82718f5a\nagile_term ['agile', 'agile']\nprocessing aa60132c-e428-3249-a984-c21c129c7f90\nagile_term ['agile', 'agile']\nprocessing 874ea93d-77da-35dd-8085-01b83c61ec5c\nagile_term ['agile', 'agile']\nprocessing 5336b881-0ba4-3af7-bc50-3e810b3eca3f\nagile_term ['agile']\nprocessing f5c8671c-42ef-313f-8161-201d52527b56\nagile_term ['agile']\nprocessing cc2f258f-c3a9-3f6c-9848-0c8a2da47fad\nagile_term ['agile']\nprocessing 9c26b3f2-659b-307b-bd96-3cc7770b6c58\nagile_term ['agile', 'agile', 'agile']\nprocessing 9622e039-6247-3027-bcd5-926c08750276\nagile_term ['agile', 'agile']\nprocessing 677b6dd0-2e86-3623-a578-476935dcdbc4\nagile_term ['agile', 'agile']\nprocessing fb495a8d-c2a3-31c7-a5cf-faa0e79c3d70\nagile_term ['agile', 'agile']\nprocessing 80fd2616-2a3f-3cf2-9077-32b7be7c6877\nagile_term ['agile']\nprocessing 8a90e5ac-a461-3b9e-b3b9-4025549cc877\nagile_term ['agile', 'agile']\nprocessing 5ea0868f-0afe-38e2-92ec-0b7e4f20f995\nagile_term ['agile', 'agile']\nprocessing dbe25578-f354-3942-99d1-7aa02a38c361\nagile_term ['agile', 'agile']\nprocessing e517dbd8-b244-3032-bcd3-ac9321cc2105\nagile_term ['agile']\nprocessing 0d31901c-2419-38fa-aa1d-7d1fe999bd5f\nagile_term ['agile', 'agile']\nprocessing 845f6d6e-8dab-3e95-8231-8c1c11510649\nagile_term ['agile', 'agile']\nprocessing cb6bae76-d9c8-3e8a-bd47-bd6fd33279fa\nagile_term ['agile', 'agile']\nprocessing b2969eef-9207-3842-a060-e30eb7952329\nagile_term ['agile']\nprocessing 7f815bf8-5435-304f-be42-82bdbecea8be\nagile_term ['agile']\nprocessing a4834898-11e5-3bdb-a4c0-a2ccfac0f9de\nagile_term ['agile']\nprocessing d8364b7b-b65c-35a8-98ea-fd7074bc242a\nagile_term ['agile', 'agile', 'agile']\nprocessing ec82980a-eba5-3403-8439-3e47b0b76b3d\nagile_term ['agile', 'agile']\nprocessing c89496b5-b89c-3604-8c0c-e5dc42789b8f\nagile_term ['agile', 'agile']\nprocessing 48c2bd16-78fd-3a24-a41d-20aa8ab99bd2\nagile_term ['agile', 'agile']\nprocessing 3679796b-7b0e-3903-93d9-7bf25a4ed2d1\nagile_term ['agile', 'agile']\nprocessing 993952fd-5dde-3949-acc6-67261cfab637\nagile_term ['agile', 'agile']\nprocessing 42400602-3d54-3b9d-a9a3-4bc5c72ff6ed\nagile_term ['agile', 'agile']\nprocessing e763ec7a-f9dd-3b0c-8ce3-b5713429d2a8\nagile_term ['agile']\nprocessing b43d38e2-3455-3ad8-9969-ed75055c2b95\nagile_term ['agile']\nprocessing d5441bb4-31b1-30fd-a14e-08b7e9060392\nagile_term ['agile', 'agile', 'agile']\nprocessing 913cb80d-7538-388b-9243-09be6df05a7c\nagile_term ['agile']\nprocessing 1d824624-1856-342b-839f-b4b4839bda72\nagile_term ['agile', 'agile']\nprocessing f6ec7310-0e07-39aa-9c23-4e81631783a6\nagile_term ['agile', 'agile']\nprocessing b37f257d-a874-38ed-baa0-580159cbf519\nagile_term ['agile', 'agile']\nprocessing 2af90275-6624-3bd4-b2a6-089b0cf7c1df\nagile_term ['agile', 'agile']\nprocessing 545ae082-eeef-32f2-8b0f-689e8a60e844\nagile_term ['agile', 'agile']\nprocessing a70afe79-09e4-3c8c-9785-4de2a42fab88\nagile_term ['agile', 'agile']\nprocessing 8afb454c-9fc2-34aa-acf2-d1801685a47a\nagile_term ['agile']\nprocessing 7feaa767-c0d5-3ea5-8298-546dc5142fe7\nagile_term ['agile']\nprocessing 27a9d751-11a3-3ed3-b87e-2109031d3f7c\nagile_term ['agile', 'agile']\nprocessing b8384b6a-29ad-31fd-8b67-0bd7cffff3c7\nagile_term ['agile', 'agile', 'agile']\nprocessing 099ac8dc-1c95-387e-83b6-1073c3beb125\nagile_term ['agile']\nprocessing dd2befd3-f69a-371f-b1c5-074f0e7cd056\nagile_term ['agile', 'agile']\nprocessing 4da80b54-90ca-37e3-9f5d-3a1799e1b190\nagile_term ['agile', 'agile']\nprocessing b26ea809-67dd-307e-9c35-ff49dd483c84\nagile_term ['agile', 'agile']\nprocessing f6a417b5-34a8-3171-9705-c231f847ec68\nagile_term ['agile', 'agile']\nprocessing 1cef62e3-f4f6-3292-beae-f523ce09bc56\nagile_term ['agile', 'agile']\nprocessing 0a433c6c-9c12-37e5-92ed-59609ecdbfab\nagile_term ['agile']\nprocessing e46651ee-d83f-3d32-b3e5-a625255d52ba\nagile_term ['agile']\nprocessing c31d84f7-724e-3d88-8c17-ebca7b0f7c94\nagile_term ['agile']\nprocessing 3fa5ded7-8131-3886-b3cc-2be1e6e477fc\nagile_term ['agile', 'agile', 'agile']\nprocessing 06fba001-0225-3515-8e78-5199fe1bb52c\nagile_term ['agile', 'agile']\nprocessing 2ef01150-6a06-3544-b2a6-232bb8731d1c\nagile_term ['agile', 'agile']\nprocessing 14cf2ab5-3e7e-3b4e-9ccf-aa7f119f2a69\nagile_term ['agile', 'agile']\nprocessing 31cac4af-215d-37ad-9f5b-dbf85c805e06\nagile_term ['agile', 'agile']\nprocessing 9643bf40-18f0-3df9-9c35-1bad19316fb4\nagile_term ['agile', 'agile']\nprocessing 6257e2cc-a893-3e5b-bbf9-d9269aaaeb45\nagile_term ['agile', 'agile']\nprocessing 4e9ff3b3-8e1b-33cb-aced-7564617e5265\nagile_term ['agile']\nprocessing 680eb322-e8ed-3e14-8f23-93658d3a47b3\nagile_term ['agile']\nprocessing cde8890a-7239-3745-bcf2-a7a1ea63f335\nagile_term ['agile', 'agile', 'agile']\nprocessing 0dedce1f-c7b7-31c6-8eb6-74ec2ebfbc0e\nagile_term ['agile']\nprocessing 0f8a422e-7340-3a8e-9b8a-553b33b5341d\nagile_term ['agile', 'agile']\nprocessing 765a23da-8d24-3bea-a950-5be5113384dc\nagile_term ['agile', 'agile']\nprocessing 3ad9e801-e461-328f-afe4-10c220c1c288\nagile_term ['agile', 'agile']\nprocessing cc3eaca3-d940-3453-bdc2-572b61133ed6\nagile_term ['agile', 'agile']\nprocessing 9495ed53-8917-3135-bdb4-41a25c3c8fd5\nagile_term ['agile', 'agile']\nprocessing c7648a97-3efb-362b-bcd4-99e9dba15cf6\nagile_term ['agile', 'agile']\nprocessing b6433e42-b16e-376e-852f-6829ff07efdb\nagile_term ['agile', 'agile', 'agile']\nprocessing f51c4939-43b9-35c4-a67e-5e99250d2a22\nagile_term ['agile']\nprocessing ac3093ba-bae2-3489-9891-6f204ff8b856\nagile_term ['agile', 'agile']\nprocessing 8155a468-2b94-3f3c-b78a-025d96fdfb28\nagile_term ['agile', 'agile']\nprocessing 5adab511-4e2f-3b71-864e-c34331233de4\nagile_term ['agile', 'agile']\nprocessing a1a99e01-c24b-32eb-b786-536e6f87dff1\nagile_term ['agile', 'agile']\nprocessing bb73fc62-f375-3be7-b2c3-7e33fec4e90a\nagile_term ['agile', 'agile']\nprocessing 090dbc8f-d76f-374d-9348-5d4356f51b1f\nagile_term ['agile', 'agile']\nprocessing 566ef813-6534-35cb-9b5e-f36f1a62678d\nagile_term ['agile']\nprocessing 1a38b65f-4670-3108-9f0f-a418b192007f\nagile_term ['agile', 'agile']\nprocessing 23831404-025b-302a-a340-4aa375e10335\nagile_term ['agile', 'agile', 'agile']\nprocessing 5d5e2662-a56d-306d-97d2-e1393ec3d4cb\nagile_term ['agile', 'agile']\nprocessing a331abe0-6f75-30c1-bef4-bc54ce32e91f\nagile_term ['agile', 'agile']\nprocessing 0b026d78-650c-36bc-a14f-4cff7ad5c09b\nagile_term ['agile', 'agile']\nprocessing 1946194c-aa77-32e9-8591-e1d51c6bb42d\nagile_term ['agile', 'agile']\nprocessing be9f0816-04f1-3a3d-83cf-51ba39a49614\nagile_term ['agile', 'agile']\nprocessing fc9a9bd8-630a-3993-b72f-fff668ac4d59\nagile_term ['agile']\nprocessing 04cf18e9-6dad-3ddb-bb76-acbc6e8dde53\nagile_term ['agile']\nprocessing c49d43ab-19c9-36c6-a9aa-d6f04a06b8a0\nagile_term ['agile']\nprocessing 7482effb-3e0b-3e53-b7a6-c58e31387805\nagile_term ['agile', 'agile', 'agile']\nprocessing 2d6b2163-83e2-336c-85c4-10c95c604827\nagile_term ['agile', 'agile']\nprocessing 2cd55f9c-0e80-3ba4-828c-07782788b882\nagile_term ['agile', 'agile']\nprocessing c58d5ebf-4a54-3162-a745-b497d94d2c00\nagile_term ['agile', 'agile']\nprocessing 7d4fb21a-3383-32fd-965f-832f4de993ce\nagile_term ['agile', 'agile']\nprocessing 3f95d1d2-1602-3225-a413-1e2fba710215\nagile_term ['agile', 'agile']\nprocessing b5925260-424f-3b47-b452-743277ceeb32\nagile_term ['agile', 'agile']\nprocessing 4e5ef193-89ad-3a69-bbdc-af070d5b745f\nagile_term ['agile']\nprocessing ad3bbcd3-d6f2-317e-9580-557e1108b98e\nagile_term ['agile']\nprocessing a0beb806-0e03-3b0a-8876-900ead2729cb\nagile_term ['agile']\nprocessing 7e9d8572-02a9-34dc-899d-e444b504b46f\nagile_term ['agile']\nprocessing 95622706-37ae-38ed-9e57-7fe6bb2bd6b1\nagile_term ['agile']\nprocessing 41da7db6-382b-34ba-aaef-c251255734d7\nagile_term ['agile']\nprocessing 311ae518-fefc-32c7-9320-088f45dcc854\nagile_term ['agile']\nprocessing f7885494-fc41-388f-badc-e0bac4c5581b\nagile_term ['agile', 'agile']\nprocessing 77f3446a-c41e-3d5f-9040-e582c2bfe573\nagile_term ['agile', 'agile', 'agile']\nprocessing dd52b21b-6faf-3d25-8096-c6d2bc7c19ff\nagile_term ['agile', 'agile']\nprocessing b40c6853-5b71-3cee-a542-a08a76e5f31f\nagile_term ['agile', 'agile']\nprocessing 366140f4-c8cd-3c01-bb7b-01797483523a\nagile_term ['agile', 'agile']\nprocessing 054531d5-61b1-3575-8ea2-ed24dbcfd2ba\nagile_term ['agile', 'agile']\nprocessing 843eaadf-2779-3b38-b071-87671185edbe\nagile_term ['agile', 'agile']\nprocessing e93345e3-90d4-33f9-95bb-6b1ddceb2925\nagile_term ['agile']\nprocessing eb516f4c-9f67-3d05-b437-1a8971db855f\nagile_term ['agile']\nprocessing 4830ecfe-daf3-3e96-af8c-7672160eb981\nagile_term ['agile']\nprocessing c2836459-b476-3f97-bcf4-f17626c32223\nagile_term ['agile', 'agile']\nprocessing d81f909a-a7be-3593-8c73-e133baeea01a\nagile_term ['agile', 'agile', 'agile']\nprocessing 1ec6f645-cc97-3a60-aec2-bd382139bbc7\nagile_term ['agile', 'agile']\nprocessing b0a3dec6-4484-3eca-af5d-657f6a0dbf85\nagile_term ['agile', 'agile']\nprocessing 8aa9ebd5-db25-3c30-b791-767f2e23695d\nagile_term ['agile', 'agile']\nprocessing 0f8abafe-490a-35e4-a2f0-ef46e8c4d531\nagile_term ['agile', 'agile']\nprocessing b435d967-0be9-3ac9-aab0-63358b156262\nagile_term ['agile', 'agile']\nprocessing 8f42bb70-8e92-3b1a-80e3-b11c79608edb\nagile_term ['agile']\nprocessing 87548b02-99e0-3db6-8ff4-2327a207db59\nagile_term ['agile']\nprocessing 7bee96da-efd4-3117-b294-ba68627c5074\nagile_term ['agile']\nprocessing 8ec12f41-7ea1-3877-9920-2c0b9764091c\nagile_term ['agile']\nprocessing 883f782f-316f-3e75-a3fe-f0f4dbdfefdc\nagile_term ['agile', 'agile']\nprocessing 07cd0e2c-ba41-3f1e-99e3-536f35c7dc7c\nagile_term ['agile', 'agile']\nprocessing b0febf7f-8fca-3555-9e74-f3b202c64479\nagile_term ['agile', 'agile', 'agile']\nprocessing add9e4be-64c6-323d-858a-b79cdd0bb23e\nagile_term ['agile', 'agile']\nprocessing a91fbe8d-665b-3c9a-bfbe-61a3b96def7f\nagile_term ['agile', 'agile']\nprocessing e80a9ab4-1bce-3da1-be09-5e8a09cb6057\nagile_term ['agile', 'agile']\nprocessing 391bdbda-7709-30b2-9fde-88a27b6b7771\nagile_term ['agile']\nprocessing dd9cb9c2-4437-3028-bd5c-aa4eb98d93c6\nagile_term ['agile', 'agile', 'agile']\nprocessing 0faeab5e-18ad-34b9-bb31-69ea83e22c68\nagile_term ['agile', 'agile']\nprocessing 6d51b063-8b9b-34cc-8ff7-425671be7903\nagile_term ['agile', 'agile']\nprocessing da026dd4-d1e3-305a-8ba0-113306b6703d\nagile_term ['agile', 'agile']\nprocessing ddd67f9c-24c2-3bb0-8a38-cb634f4db312\nagile_term ['agile', 'agile']\nprocessing 1bce006b-5046-3f95-8a3c-6efcc9dc77ce\nagile_term ['agile', 'agile']\nprocessing 4c82f2e0-fe6d-3b30-836b-48e79da3b306\nagile_term ['agile', 'agile']\nprocessing 54fdcbdb-7b8d-3102-9538-9edacf3e4e9d\nagile_term ['agile']\nprocessing 4244da25-0b1b-386a-bde2-d198ce1bfceb\nagile_term ['agile']\nprocessing ead46699-e9fe-3981-8202-70e1f3d4b096\nagile_term ['agile', 'agile']\nprocessing b37b2e4e-591e-3241-bff1-91a6c230ba59\nagile_term ['agile']\nprocessing 852f586f-a628-3151-ae5c-57e3301677d7\nagile_term ['agile']\nprocessing 99caacca-fa51-3367-a30a-8e19fec806f0\nagile_term ['agile', 'agile']\nprocessing efbb28f5-a14b-36c0-9c20-73a98e5ffb0c\nagile_term ['agile']\nprocessing 03a644a8-817e-31ee-8a50-57127e54bbcb\nagile_term ['agile', 'agile', 'agile']\nprocessing aaebd192-67e7-3768-ad35-27c09c9cb5ff\nagile_term ['agile', 'agile']\nprocessing 2df02b57-352e-3814-b899-8fe7f385e62a\nagile_term ['agile', 'agile']\nprocessing 37dec61a-67f6-336a-99eb-eb44e5360a38\nagile_term ['agile', 'agile']\nprocessing 0015858e-eb45-3ab6-a7f6-99f319b57e64\nagile_term ['agile', 'agile']\nprocessing 62f52822-9502-39e7-9ebb-16d4a9b5bfe2\nagile_term ['agile']\nprocessing 1b0dc6f7-f919-3a62-8d87-a816de465c9e\nagile_term ['agile', 'agile']\nprocessing db1bc3e7-ae5d-3277-aeec-a2ff6fb2726c\nagile_term ['agile']\nprocessing 2df0a28c-9892-3b36-9fea-d371990e0ab2\nagile_term ['agile']\nprocessing ed99b582-ae3a-3e8e-a21d-b5862e7bc37c\nagile_term ['agile', 'agile']\nprocessing 3a560600-d34c-3388-b216-03ddbe4e16a4\nagile_term ['agile', 'agile', 'agile']\nprocessing 852e0c10-8fd1-376e-969b-bb2e2d9cb097\nagile_term ['agile', 'agile']\nprocessing 36702d30-64ed-3538-8959-4af9c1590f70\nagile_term ['agile', 'agile']\nprocessing f55393db-9cb2-3dee-b926-6da77e24840e\nagile_term ['agile', 'agile']\nprocessing 9b05c156-dd54-3046-b27c-88b7825fb51c\nagile_term ['agile', 'agile']\nprocessing c32f0e93-6a84-398f-993d-f589c10674b1\nagile_term ['agile', 'agile']\nprocessing 2e581bce-ee99-3839-8388-847df9fec7a5\nagile_term ['agile', 'agile', 'agile']\nprocessing 89bf5122-a66c-35ec-a5ab-50e7f13131b5\nagile_term ['agile']\nprocessing aab15b12-1414-32c3-9e2d-89fc38195272\nagile_term ['agile', 'agile']\nprocessing 1cee52b5-3c88-3c8d-9a88-d2d6c8f31020\nagile_term ['agile', 'agile']\nprocessing 5f0d0a4e-a457-3a63-9c51-69ad42aac08f\nagile_term ['agile', 'agile']\nprocessing 3a3fccc7-a597-3685-affb-677bd1be88de\nagile_term ['agile']\nprocessing 31a0230c-bab8-3ff2-8300-7ea12af79490\nagile_term ['agile', 'agile']\nprocessing 1dfb7dcc-2927-3921-8332-bc091f57e165\nagile_term ['agile', 'agile']\nprocessing c3f8f06e-810f-3d0c-9f63-d40c3358c7b2\nagile_term ['agile']\nprocessing 60c9907f-dc02-3bce-98f4-b576c29fc09f\nagile_term ['agile', 'agile']\nprocessing d6b17ca6-bbd4-31a6-943a-43be5a8706ed\nagile_term ['agile', 'agile', 'agile']\nprocessing 6c80d77a-86da-3e2c-9fe3-06b52221a52d\nagile_term ['agile']\nprocessing f3a18ba2-6e4e-347c-a601-e41a399f62eb\nagile_term ['agile', 'agile']\nprocessing ae7c66b3-8f2b-33d8-aef9-fbb44ee8539e\nagile_term ['agile', 'agile']\nprocessing 6714d561-4943-3b30-94c1-afcdac842825\nagile_term ['agile', 'agile']\nprocessing ef138304-8f7b-3750-8149-d203dc95b12b\nagile_term ['agile', 'agile']\nprocessing eceb6031-df2e-3d61-b67e-a611ac07abb6\nagile_term ['agile', 'agile']\nprocessing 13c58f89-9454-3880-862c-a64f87f44b00\nagile_term ['agile']\nprocessing 12e5d6f1-b73d-31d1-a918-1b894b554156\nagile_term ['agile']\nprocessing 96b0fceb-723c-3e9c-84ef-cc732eb3a6ad\nagile_term ['agile']\nprocessing 31bbea36-4f06-371a-a2f0-adfc4bb4fa2b\nagile_term ['agile', 'agile']\nprocessing 27fd05f2-135d-3ec9-ad0a-c102df0ad541\nagile_term ['agile', 'agile']\nprocessing d5547c9b-92d2-3e91-95b7-44853b39d277\nagile_term ['agile', 'agile']\nprocessing 7162de85-f19c-3306-a6f6-0e7c7f4389b4\nagile_term ['agile', 'agile']\nprocessing 9275806f-005b-3ed7-9904-926abbb8072c\nagile_term ['agile', 'agile']\nprocessing 23e8f1e5-a666-3e05-bb5b-9ce50b55a088\nagile_term ['agile', 'agile', 'agile']\nprocessing 4ae75663-d968-3d3d-bf7e-386cb6132a9b\nagile_term ['agile', 'agile']\nprocessing 19d31e70-1ea2-3fe4-ad6e-2cb9bfa46daf\nagile_term ['agile']\nprocessing fb1e1778-7639-385d-bc54-e9fa5e6c3329\nagile_term ['agile']\nprocessing 2a2d0d37-1e7e-3d31-915a-c47942a24264\nagile_term ['agile', 'agile']\nprocessing 146d59cb-7dd3-3101-b51c-6d994516ac73\nagile_term ['agile']\nprocessing b1bee9c5-5922-36b2-b5e1-1a04c997c7bd\nagile_term ['agile']\nprocessing 4107e0d3-fdfe-3692-88e8-aad31d347acf\nagile_term ['agile', 'agile']\nprocessing f7a1d726-e8bf-3344-a0cd-e2d329a29ac8\nagile_term ['agile', 'agile']\nprocessing b393e9ad-e62b-3808-97fb-9bb33a9310c2\nagile_term ['agile', 'agile']\nprocessing 8011bd2d-71fb-3255-9d43-f4cf202744f3\nagile_term ['agile', 'agile', 'agile']\nprocessing ad15fb28-372e-364a-974f-70386c6e64d6\nagile_term ['agile', 'agile']\nprocessing 82ed3b11-4911-304b-bfec-f56eb7cab6cb\nagile_term ['agile', 'agile']\nprocessing ddaf73fc-e1b1-3a08-b934-8129762dba5f\nagile_term ['agile', 'agile']\nprocessing fa4b751f-4b6c-30c9-ae01-ef960daef2ae\nagile_term ['agile']\nprocessing 46970c87-f928-3dbb-9290-29155ed3c8c9\nagile_term ['agile']\nprocessing e22d01e8-915e-338b-9441-8c45648529f0\nagile_term ['agile']\nprocessing 12a6f03f-7290-34f3-a77d-a3a2fc7c4fdc\nagile_term ['agile']\nprocessing f790c7a4-57ae-31e5-b52a-4b0335b7e71f\nagile_term ['agile', 'agile', 'agile', 'agile']\nprocessing a950a20b-29d8-30db-aae6-8d66165672ce\nagile_term []\nprocessing f9f62e29-95fe-3ea6-b566-6f0ecc606dfc\nagile_term ['agile', 'agile']\nprocessing 5549d07c-2468-3299-acf1-74f91ac839d2\nagile_term ['agile']\nprocessing 0d7079ae-c8c5-3717-be73-2279b3a5a34c\nagile_term ['agile', 'agile']\nprocessing a6dbeb74-7b9a-316b-8775-97a9d1992f5b\nagile_term ['agile']\nprocessing 1d1ab5ca-9a17-39f8-ba5c-85ec2847fb40\nagile_term ['agile', 'agile']\nprocessing 63a39a44-3034-376d-8d9c-151064e3802d\nagile_term ['agile', 'agile']\nprocessing 73541b94-2bbc-3326-ba73-1903cf12a1ae\nagile_term []\nprocessing 53e4c396-8d56-3d87-8e41-181ff8e55b0f\nagile_term ['agile']\nprocessing c9a3bdda-5402-3125-a351-cad2391dd17f\nagile_term ['agile']\nprocessing 1dab1245-b31e-3eec-9ac9-7596c8fcdcaf\nagile_term ['agility,']\nprocessing 4b8cccaf-d9da-3526-9c35-c0f4c9687186\nagile_term ['agile']\nprocessing 9d62d413-2498-3a33-b322-d6316a626354\nagile_term ['agile', 'agility']\nprocessing 8e680286-eaa7-3035-b4e8-c9e12ef14d6e\nagile_term ['agile']\nprocessing da9af499-150d-301a-b748-62229d0afb48\nagile_term ['agile']\nprocessing a53a2d10-6fcb-34b6-9ed3-984bf967051f\nagile_term ['agile', 'agility,']\nprocessing 5e95e196-dc45-3752-8202-fd35b753ae65\nagile_term ['agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile']\nprocessing e8452df1-52a2-32b4-83eb-d7ad5925dd95\nagile_term []\nprocessing 7af310d7-bfda-38d0-ab44-ca61609cf4f9\nagile_term ['agile']\nprocessing bd1de351-93e2-36bc-b7dd-4cf303949659\nagile_term ['agile', 'agility']\nprocessing b252e189-d15d-304f-869b-c3ea57b5c858\nagile_term ['agile']\nprocessing 4ae13f60-9e14-36f8-baac-35a73b6a573b\nagile_term ['agile']\nprocessing 7850a7ab-01c0-3f2e-b8a5-c15379f93e50\nagile_term ['agile']\nprocessing 2ca46f2e-d1e9-3265-8b08-e020a7a9ca1a\nagile_term ['agile']\nprocessing 0921236d-a358-3ed2-8030-5f6768925849\nagile_term []\nprocessing eb083253-8b91-32de-8cf5-c7b0a138dab6\nagile_term ['agile']\nprocessing 9e7a1efe-34dd-3621-a984-c0475a98251d\nagile_term []\nprocessing e388d426-9c60-3260-8561-8cffb47c7fb6\nagile_term ['agile']\nprocessing fe883b70-932d-3591-b22d-de837a3a4a47\nagile_term ['agile', 'agile', 'agile', 'agile', 'agile']\nprocessing e5901c84-2ca9-3a97-8723-9d60d573c491\nagile_term ['agile']\nprocessing 84e852d3-e6b0-3796-8e4f-dd79df6ac60b\nagile_term []\nprocessing 871c28e9-798e-3196-abd1-9262f43655c8\nagile_term ['agile']\nprocessing 76987ad2-62a9-31b9-85be-83531438a4aa\nagile_term ['agile']\nprocessing 6854153f-ca0a-3332-8852-0256031bfbde\nagile_term ['agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile']\nprocessing b6ea474c-de97-3d4f-89b0-ee4e67e3e6ca\nagile_term ['agile', 'agile', 'agile', 'agile']\nprocessing 69d46b3f-17a9-3792-9db9-9acf64a17443\nagile_term ['agile', 'agile', 'agile', 'agile']\nprocessing 453f7ead-f091-3576-97db-8316df2825a6\nagile_term ['agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile']\nprocessing 8706907d-3b1a-3f3a-a2f2-2b2cdc179bbf\nagile_term ['agile']\nprocessing 13848e40-25e5-34b6-8b3c-32381234a360\nagile_term ['agile', 'agile']\nprocessing 7b8f367f-4a0f-39b5-8971-794b83e180ff\nagile_term ['agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile']\nprocessing c2684060-e94d-3f3a-8437-cd013eaa030b\nagile_term ['agile', 'agile', 'agile', 'agile', 'agile', 'agile']\nprocessing d16f7937-fdb2-391b-868e-864ffe10067e\nagile_term ['agile']\nprocessing ebefeb60-844f-3c4f-bc35-9380fb5286fb\nagile_term ['agile,']\nprocessing a6e770c0-5cb5-303a-b443-00cc958f3807\nagile_term ['agile']\nprocessing 3c111193-9f3e-3be6-8d5e-a6ee3056dda1\nagile_term ['agile']\nprocessing b1bacb13-a7e0-34f8-9bf9-2e4202c511cc\nagile_term ['agile']\nprocessing 4b00f33c-876b-3d78-9dcc-97b98a3e1c2d\nagile_term ['agile', 'agile', 'agile', 'agile,', 'agile']\nprocessing 16fef62e-2898-3431-b0c6-3ea138618812\nagile_term ['agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile,', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile', 'agile']\n"
    }
   ],
   "source": [
    "#Running processing for UK\n",
    "process_state_UK(\"General\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Cleaning State Germany\n",
    "def cleaning_state_DE(state):\n",
    "    inputFileName = \"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/2_Data_Processing/DATA/CSVs/Germany/{}.csv\".format(state)\n",
    "    outputFileName = \"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/2_Data_Processing/DATA/CSVs/Germany/{}_v1.csv\".format(state)\n",
    "\n",
    "    with open(inputFileName, newline='') as inFile, open(outputFileName, 'w', newline='') as outFile:\n",
    "        df = pd.read_csv(inFile)\n",
    "        df.sort_values(by=['final_date'])\n",
    "        df.dropna(axis=0, how='any', thresh=None, subset=(['agile_term', 'agile_context_pre', 'agile_context_post']), inplace=True)\n",
    "        df.drop_duplicates(subset=(['heading', 'agile_context_pre', 'agile_context_post']), inplace=True)\n",
    "        df['heading'] = df['heading'].astype(str)\n",
    "        #deleting false positives\n",
    "        df = df[~df.agile_context_post.str.startswith(\"(\")] # dropdown menu entry\n",
    "        df = df[~df.agile_context_pre.str.endswith(\")\")] # dropdown menu entry\n",
    "\n",
    "        df.to_csv(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Cleaning State UK\n",
    "def cleaning_state_UK(state):\n",
    "    inputFileName = \"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/2_Data_Processing/DATA/CSVs/UK/{}.csv\".format(state)\n",
    "    outputFileName = \"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GitHubRepo/agile-in-government/Analysis/2_Data_Processing/DATA/CSVs/UK/{}_v1.csv\".format(state)\n",
    "\n",
    "    with open(inputFileName, newline='') as inFile, open(outputFileName, 'w', newline='') as outFile:\n",
    "        df = pd.read_csv(inFile)\n",
    "        df.sort_values(by=['final_date'])\n",
    "        df.dropna(axis=0, how='any', thresh=None, subset=(['agile_term', 'agile_context_pre', 'agile_context_post']), inplace=True)\n",
    "        df.drop_duplicates(subset=(['heading', 'agile_context_pre', 'agile_context_post']), inplace=True)\n",
    "        df['heading'] = df['heading'].astype(str)\n",
    "        #deleting false positives\n",
    "        df = df[~df.agile_context_post.str.startswith(\"(\")] # dropdown menu entry\n",
    "        df = df[~df.agile_context_pre.str.endswith(\")\")] # dropdown menu entry\n",
    "        df = df[~df.agile_context_pre.str.endswith(\"EB\")] # supplier list\n",
    "        df = df[~df.agile_context_post.str.match('and battle-winning armed forces')] #army related agility\n",
    "        df = df[~df.agile_context_pre.str.match('Atom CategoriesCategories Select Category')] # dopdown menu entry\n",
    "        df = df[~df.agile_context_pre.str.match('RAF to Force Generate')] # Entry on Air Commanders\n",
    "        df = df[~df.agile_context_post.str.startswith(\"Trains\")] # name of a company \"Agility Trains\"\n",
    "        df = df[~df.agile_context_post.str.startswith(\"trains\")] # name of a company \"Agility Trains\"\n",
    "        df.to_csv(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaning_state_DE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ada40f4a060c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Cleaning State Germany\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcleaning_state_DE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'insert_state_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaning_state_DE' is not defined"
     ]
    }
   ],
   "source": [
    "#Cleaning State Germany\n",
    "cleaning_state_DE('insert_state_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning State UK\n",
    "cleaning_state_UK('General')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### END OF ANALYSIS ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Combining all the Data Frames into one with pandas ########\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2019-05-29T12:44:02+00:00\n"
    }
   ],
   "source": [
    "#tester for getting dates with Xpath\n",
    "\n",
    "htmlparser = etree.HTMLParser()    \n",
    "try:\n",
    "    tree = etree.parse(open(\"/Users/mxm/Google Drive/Masterstudium/Inhalte/Master Thesis/GithubRepository/Analysis/ALL_CRAWLS/Germany/Federal/www.westmidlands-pcc.gov.uk/765598f5-dc1c-3af2-94a6-96bd59ad0c44.html\", \"r\"), htmlparser)\n",
    "except UnicodeDecodeError:\n",
    "    tree = etree.parse(open(path, encoding='windows-1252'), htmlparser)\n",
    "date8 = tree.xpath(\"substring(substring-after(/html//script[@type='application/ld+json']/text(), 'datePublished'), 4, 25)\")\n",
    "print(date8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[' ']\n"
    }
   ],
   "source": [
    "#testing regex expressions\n",
    "agile_regex = re.compile(r'\\bagile\\b(?:(?![.]|agile).)*?\\bmethod\\w*?\\b', re.IGNORECASE | re.UNICODE)\n",
    "text = 'agile teams            To help people in policy or related areas understand what digital means in government, exploring the methodology'\n",
    "print(agile_regex.findall(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('Scraper_v1': conda)",
   "language": "python",
   "name": "python37664bitscraperv1condac67eee00092f451cb06b7dadff488d14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}